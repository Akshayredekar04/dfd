{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchaudio pytorch-lightning transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "# from multiprocessing import Pool\n",
    "# from functools import partial\n",
    "\n",
    "# def copy_file(args):\n",
    "#     \"\"\"Helper function to copy a single file and handle errors.\"\"\"\n",
    "#     src, dest = args\n",
    "#     try:\n",
    "#         shutil.copy(src, dest)\n",
    "#         return None  # Success\n",
    "#     except (OSError, shutil.Error) as e:\n",
    "#         return f\"Error copying {src}: {e}\"\n",
    "\n",
    "# def split_audio_dataset(base_real, base_fake, output_base, train_ratio=0.8, val_ratio=0.1, num_processes=4):\n",
    "#     # Supported audio extensions\n",
    "#     valid_extensions = {'.wav', '.mp3', '.flac', '.ogg', '.m4a'}\n",
    "\n",
    "#     # Create output directories\n",
    "#     for split in [\"train\", \"val\", \"test\"]:\n",
    "#         for label in [\"real\", \"fake\"]:\n",
    "#             Path(os.path.join(output_base, split, label)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     def split_and_copy(files, label):\n",
    "#         random.shuffle(files)\n",
    "#         total = len(files)\n",
    "#         if total == 0:\n",
    "#             print(f\"Warning: No files found for {label}.\")\n",
    "#             return\n",
    "\n",
    "#         train_end = int(train_ratio * total)\n",
    "#         val_end = train_end + int(val_ratio * total)\n",
    "\n",
    "#         splits = {\n",
    "#             \"train\": files[:train_end],\n",
    "#             \"val\": files[train_end:val_end],\n",
    "#             \"test\": files[val_end:]\n",
    "#         }\n",
    "\n",
    "#         # Copy files using multiprocessing\n",
    "#         for split, file_list in splits.items():\n",
    "#             print(f\"Copying {len(file_list)} files to {split}/{label}...\")\n",
    "#             # Prepare source-destination pairs\n",
    "#             dest_dir = os.path.join(output_base, split, label)\n",
    "#             copy_tasks = [(f, os.path.join(dest_dir, os.path.basename(f))) for f in file_list]\n",
    "            \n",
    "#             # Use multiprocessing Pool\n",
    "#             with Pool(processes=num_processes) as pool:\n",
    "#                 # Use tqdm for progress tracking\n",
    "#                 errors = list(tqdm(\n",
    "#                     pool.imap_unordered(copy_file, copy_tasks),\n",
    "#                     total=len(copy_tasks),\n",
    "#                     desc=f\"{split}/{label}\",\n",
    "#                     unit=\"file\"\n",
    "#                 ))\n",
    "            \n",
    "#             # Log any errors\n",
    "#             for error in errors:\n",
    "#                 if error:\n",
    "#                     print(error)\n",
    "\n",
    "#         return splits\n",
    "\n",
    "#     # Collect files with valid extensions\n",
    "#     real_files = [\n",
    "#         os.path.join(base_real, f) for f in os.listdir(base_real)\n",
    "#         if os.path.splitext(f)[1].lower() in valid_extensions\n",
    "#     ]\n",
    "#     fake_files = [\n",
    "#         os.path.join(base_fake, f) for f in os.listdir(base_fake)\n",
    "#         if os.path.splitext(f)[1].lower() in valid_extensions\n",
    "#     ]\n",
    "\n",
    "#     # Verify input directories\n",
    "#     if not real_files:\n",
    "#         print(f\"Warning: No valid audio files found in {base_real}\")\n",
    "#     if not fake_files:\n",
    "#         print(f\"Warning: No valid audio files found in {base_fake}\")\n",
    "\n",
    "#     print(f\"Found {len(real_files)} real and {len(fake_files)} fake files.\")\n",
    "\n",
    "#     # Perform split and copy\n",
    "#     real_splits = split_and_copy(real_files, \"real\")\n",
    "#     fake_splits = split_and_copy(fake_files, \"fake\")\n",
    "\n",
    "#     # Log split sizes\n",
    "#     if real_splits and fake_splits:\n",
    "#         for split in [\"train\", \"val\", \"test\"]:\n",
    "#             real_count = len(real_splits[split])\n",
    "#             fake_count = len(fake_splits[split])\n",
    "#             print(f\"{split.capitalize()} split: {real_count} real, {fake_count} fake\")\n",
    "\n",
    "#     print(\"Done splitting into train, val, test.\")\n",
    "\n",
    "# # Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     split_audio_dataset(\n",
    "#         base_real=\"/teamspace/studios/this_studio/audio_detect/dataset/processed_data_2s/real\",\n",
    "#         base_fake=\"/teamspace/studios/this_studio/audio_detect/dataset/processed_data_2s/fake\",\n",
    "#         output_base=\"/teamspace/studios/this_studio/audio_detect/dataset/split_data\",\n",
    "#         num_processes=4  # Adjust based on your CPU cores\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# def count_files(directory):\n",
    "#     return sum([len(files) for _, _, files in os.walk(directory)])\n",
    "\n",
    "# train_real_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/train/real\"\n",
    "# val_real_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/val/real\"\n",
    "# test_real_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/test/real\"\n",
    "# train_fake_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/train/fake\"\n",
    "# val_fake_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/val/fake\"\n",
    "# test_fake_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/test/fake\"\n",
    "\n",
    "# print(\"Train real files:\", count_files(train_real_dir))\n",
    "# print(\"Validation real files:\", count_files(val_real_dir))\n",
    "# print(\"Test real files:\", count_files(test_real_dir))\n",
    "\n",
    "# print(\"Train fake files:\", count_files(train_fake_dir))\n",
    "# print(\"Validation fake files:\", count_files(val_fake_dir))\n",
    "# print(\"Test fake files:\", count_files(test_fake_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torchaudio\n",
    "# import random\n",
    "# from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "# from transformers import Wav2Vec2Processor\n",
    "\n",
    "# # Check for GPU availability\n",
    "# if not torch.cuda.is_available():\n",
    "#     print(\"Warning: No GPU detected. Training on CPU will be significantly slower.\")\n",
    "\n",
    "# # Custom dataset for real/fake audio\n",
    "# class AudioDataset(Dataset):\n",
    "#     def __init__(self, data_dir, processor, label, extensions=(\".wav\", \".mp3\", \".flac\", \".ogg\", \".m4a\")):\n",
    "#         \"\"\"\n",
    "#         Initialize the dataset for real or fake audio files.\n",
    "        \n",
    "#         Args:\n",
    "#             data_dir (str): Directory containing audio files.\n",
    "#             processor (Wav2Vec2Processor): Processor for Wav2Vec2 model.\n",
    "#             label (int): Label for the class (0 for real, 1 for fake).\n",
    "#             extensions (tuple): File extensions to filter (default: '.wav', '.mp3', '.flac', '.ogg', '.m4a').\n",
    "#         \"\"\"\n",
    "#         self.files = [\n",
    "#             os.path.join(data_dir, f) for f in os.listdir(data_dir)\n",
    "#             if f.lower().endswith(extensions) and os.path.isfile(os.path.join(data_dir, f))\n",
    "#         ]\n",
    "#         self.processor = processor\n",
    "#         self.label = label\n",
    "#         if not self.files:\n",
    "#             print(f\"Warning: No valid audio files found in {data_dir}\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         file_path = self.files[idx]\n",
    "#         try:\n",
    "#             waveform, sr = torchaudio.load(file_path)\n",
    "#             # Ensure 16kHz sampling rate (Wav2Vec2 requirement)\n",
    "#             if sr != 16000:\n",
    "#                 resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "#                 waveform = resampler(waveform)\n",
    "#             # Ensure mono audio (Wav2Vec2 expects 1D input)\n",
    "#             if waveform.shape[0] > 1:\n",
    "#                 waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "#             waveform = waveform.squeeze(0)  # Remove channel dim\n",
    "#             # Process waveform with Wav2Vec2Processor\n",
    "#             inputs = self.processor(\n",
    "#                 waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True\n",
    "#             )\n",
    "#             return {\n",
    "#                 \"input_values\": inputs.input_values.squeeze(0),\n",
    "#                 \"attention_mask\": inputs.attention_mask.squeeze(0),\n",
    "#                 \"labels\": torch.tensor(self.label, dtype=torch.long)\n",
    "#             }\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading {file_path}: {e}\")\n",
    "#             # Return a random item to avoid infinite recursion\n",
    "#             return self.__getitem__(random.randint(0, self.__len__() - 1))\n",
    "\n",
    "# # Create DataLoaders\n",
    "# def create_dataloaders(train_real_dir, train_fake_dir, val_real_dir, val_fake_dir, processor, batch_size=16):\n",
    "#     \"\"\"\n",
    "#     Create DataLoaders for training and validation datasets, optimized for GPU.\n",
    "    \n",
    "#     Args:\n",
    "#         train_real_dir (str): Directory for training real audio.\n",
    "#         train_fake_dir (str): Directory for training fake audio.\n",
    "#         val_real_dir (str): Directory for validation real audio.\n",
    "#         val_fake_dir (str): Directory for validation fake audio.\n",
    "#         processor (Wav2Vec2Processor): Processor for Wav2Vec2 model.\n",
    "#         batch_size (int): Batch size for DataLoader (default: 16, adjust to 8 for smaller GPUs).\n",
    "    \n",
    "#     Returns:\n",
    "#         tuple: (train_loader, val_loader)\n",
    "#     \"\"\"\n",
    "#     # Initialize datasets\n",
    "#     train_real = AudioDataset(train_real_dir, processor, label=0)\n",
    "#     train_fake = AudioDataset(train_fake_dir, processor, label=1)\n",
    "#     val_real = AudioDataset(val_real_dir, processor, label=0)\n",
    "#     val_fake = AudioDataset(val_fake_dir, processor, label=1)\n",
    "\n",
    "#     # Check for empty datasets\n",
    "#     for dataset, name in [\n",
    "#         (train_real, \"train_real\"), (train_fake, \"train_fake\"),\n",
    "#         (val_real, \"val_real\"), (val_fake, \"val_fake\")\n",
    "#     ]:\n",
    "#         if len(dataset) == 0:\n",
    "#             raise ValueError(f\"No audio files found in {name} directory\")\n",
    "\n",
    "#     # Combine real and fake datasets\n",
    "#     train_dataset = ConcatDataset([train_real, train_fake])\n",
    "#     val_dataset = ConcatDataset([val_real, val_fake])\n",
    "\n",
    "#     # Create DataLoaders with GPU optimizations\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=True,\n",
    "#         num_workers=4,  # Parallel data loading for GPU\n",
    "#         pin_memory=True  # Fast data transfer to GPU\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=False,\n",
    "#         num_workers=4,  # Parallel data loading for GPU\n",
    "#         pin_memory=True  # Fast data transfer to GPU\n",
    "#     )\n",
    "#     return train_loader, val_loader\n",
    "\n",
    "# # Paths and processor\n",
    "# train_real_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/train/real\"\n",
    "# train_fake_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/train/fake\"\n",
    "# val_real_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/val/real\"\n",
    "# val_fake_dir = \"/teamspace/studios/this_studio/audio_detect/dataset/split_data/val/fake\"\n",
    "\n",
    "# # Load processor\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "# # Initialize DataLoaders\n",
    "# train_loader, val_loader = create_dataloaders(\n",
    "#     train_real_dir, train_fake_dir, val_real_dir, val_fake_dir, processor, batch_size=16\n",
    "# )\n",
    "\n",
    "# # Debug first batch to confirm GPU compatibility\n",
    "# for batch in train_loader:\n",
    "#     print(\"Input shape:\", batch[\"input_values\"].shape)\n",
    "#     print(\"Attention mask shape:\", batch[\"attention_mask\"].shape)\n",
    "#     print(\"Labels shape:\", batch[\"labels\"].shape)\n",
    "#     # Example: Move batch to GPU (will be handled by PyTorch Lightning in training)\n",
    "#     if torch.cuda.is_available():\n",
    "#         batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "#         print(\"Batch moved to GPU:\", batch[\"input_values\"].device)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# %pip uninstall torchaudio\n",
    "# %pip install torchaudio --index-url https://download.pytorch.org/whl/cu128\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
